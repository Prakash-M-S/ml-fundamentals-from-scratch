# Machine Learning Fundamentals from Scratch ğŸ¤–

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![NumPy](https://img.shields.io/badge/NumPy-1.21+-orange.svg)](https://numpy.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **From Theory to Practice**: Complete implementations of fundamental machine learning algorithms following Andrew Ng's Machine Learning Specialization.

## ğŸ¯ Project Overview

This repository contains **from-scratch implementations** of core machine learning algorithms, built to understand the mathematical foundations before using high-level libraries. Each implementation is validated against scikit-learn for correctness.

### ğŸš€ What's Inside

| Algorithm | Problem Type | Dataset | Key Features |
|-----------|-------------|---------|--------------|
| **Linear Regression** | Regression | Bike Sharing | Gradient Descent, Ridge Regularization, Cross-Validation |
| **Logistic Regression** | Classification | Pulsar Detection | Sigmoid, Cross-Entropy, L2 Regularization, Stratified Sampling |

## ğŸ“Š Results Summary

### Linear Regression - Bike Rental Prediction
- **MAE**: 651.99 (vs sklearn: 651.96) - 99.99% agreement
- **RMSE**: 859.36 rentals
- **Cross-Validation**: 5-fold CV with low variance (2.8% coefficient of variation)
- **Features**: 9 weather and temporal features predicting daily bike rentals

### Logistic Regression - Pulsar Detection
- **Accuracy**: 98.16% 
- **Precision**: 96.48%
- **Recall**: 83.12%
- **F1-Score**: 89.30%
- **Perfect sklearn validation** across all metrics

## ğŸ› ï¸ Technical Implementations

### Core Algorithms
- âœ… **Custom Gradient Descent** with learning rate optimization
- âœ… **Feature Scaling** (Z-score normalization)
- âœ… **Regularization** (L2/Ridge for both algorithms)
- âœ… **Cross-Validation** for robust evaluation
- âœ… **Stratified Sampling** for imbalanced datasets

### Advanced Features
- âœ… **Overfitting Analysis** with comprehensive diagnostics
- âœ… **Learning Curve Visualization** 
- âœ… **Numerical Stability** (epsilon handling)
- âœ… **Multiple Evaluation Metrics**
- âœ… **Scikit-learn Validation** for correctness verification

## ğŸ“ Repository Structure

```
ml-regression-projects/
â”œâ”€â”€ linear_regression_bikes/
â”‚   â”œâ”€â”€ data/day.csv                    # Bike sharing dataset
â”‚   â”œâ”€â”€ notebooks/scratch.ipynb         # Complete implementation
â”‚   â”œâ”€â”€ results/                        # Visualizations and plots
â”‚   â””â”€â”€ README.md                       # Detailed project docs
â”œâ”€â”€ logistic_regression_pulsar/
â”‚   â”œâ”€â”€ data/pulsar_data_train.csv      # Pulsar detection dataset
â”‚   â”œâ”€â”€ notebooks/scratch.ipynb         # Complete implementation  
â”‚   â”œâ”€â”€ results/                        # Visualizations and plots
â”‚   â””â”€â”€ README.md                       # Detailed project docs
â”œâ”€â”€ requirements.txt                     # Dependencies
â””â”€â”€ README.md                           # This file
```

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install -r requirements.txt
```

### Run the Projects
```bash
# Linear Regression
cd linear_regression_bikes/notebooks/
jupyter notebook scratch.ipynb

# Logistic Regression  
cd logistic_regression_pulsar/notebooks/
jupyter notebook scratch.ipynb
```

## ğŸ“ Learning Outcomes

### Mathematical Foundations
- **Gradient Descent**: Understanding parameter optimization mechanics
- **Cost Functions**: MSE for regression, Cross-entropy for classification
- **Regularization**: Bias-variance tradeoff and overfitting prevention
- **Feature Engineering**: Scaling, normalization, and preprocessing

### Implementation Skills
- **NumPy Vectorization**: Efficient mathematical operations
- **Algorithm Design**: Clean, modular function architecture
- **Validation Methodology**: Train/test splits, cross-validation, metrics
- **Debugging**: Mathematical correctness verification

### Professional Practices
- **Documentation**: Clear README files with results and methodology
- **Reproducibility**: Seeded random states and consistent preprocessing
- **Visualization**: Learning curves, performance plots, diagnostic charts
- **Version Control**: Clean Git history with meaningful commits

## ğŸ” Validation & Quality Assurance

- âœ… **Perfect Sklearn Agreement**: All implementations match sklearn results
- âœ… **Cross-Validation Stability**: Low variance across different data splits
- âœ… **Overfitting Analysis**: Comprehensive diagnostics confirm model generalization
- âœ… **Code Quality**: Clean, documented, modular implementations

## ğŸŒŸ Key Insights

> *"Sometimes the best way to understand a model is to build it from nothing."*

1. **Gradient Descent Intuition**: Watching cost functions converge builds deep understanding
2. **Regularization Necessity**: L2 penalty prevents overfitting in practice
3. **Scaling Criticality**: Feature normalization dramatically improves convergence
4. **Validation Importance**: Multiple evaluation methods catch edge cases

## ğŸ“ˆ What's Next

- [ ] Neural Networks from scratch
- [ ] Support Vector Machines
- [ ] Decision Trees and Random Forests
- [ ] Advanced optimization algorithms (Adam, RMSprop)

## ğŸ™ Acknowledgments

Built following **Andrew Ng's Machine Learning Specialization** (Supervised ML course). The mathematical foundations and best practices learned from the course made these implementations possible.

---

### ğŸ“« Connect & Discuss

- **LinkedIn**: [Prakash M S](https://www.linkedin.com/in/prakash-saravanan-858113284/)
- **GitHub**: [@Prakash-M-S](https://github.com/Prakash-M-S)

*Happy to discuss machine learning fundamentals, implementation details, or career opportunities!*

---

**â­ Star this repo if you found it helpful for learning ML fundamentals!**
